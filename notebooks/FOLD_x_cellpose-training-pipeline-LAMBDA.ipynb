{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y -q yellowbrick\n",
    "\n",
    "!pip install -q tifffile # contains tools to operate tiff-files\n",
    "!pip install -q folium==0.2.1\n",
    "!pip install -q imgaug==0.2.5\n",
    "!pip install -q opencv-python==3.4.5.20\n",
    "!pip install -q numpy==1.20.0\n",
    "!pip install -q cellpose \n",
    "!pip install -q wget\n",
    "!pip install -q memory_profiler\n",
    "!pip install -q fpdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising Flows\n",
    "#### 5-fold data Generated in cellpose format here: https://www.kaggle.com/ks2019/sartorius-train-tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.path.join('/home/ubuntu/kaggle-sartorius/')\n",
    "RAW_DATA = os.path.join(HOME,'data/raw')\n",
    "INTERIM_DATA = os.path.join(HOME,'data/interim')\n",
    "PROCESSED_DATA = os.path.join(HOME,'data/processed')\n",
    "\n",
    "TRAIN_CSV  = os.path.join(RAW_DATA,'train.csv')  \n",
    "TRAIN_PATH = os.path.join(RAW_DATA,'train')  \n",
    "TEST_PATH  = os.path.join(RAW_DATA,'test')  \n",
    "MODELS_PATH = os.path.join(HOME,'models')\n",
    "os.environ[\"CELLPOSE_LOCAL_MODELS_PATH\"] = MODELS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(img_path):\n",
    "    mask_path = img_path.replace('img','masks')\n",
    "    flow_path = img_path.replace('img','flows')\n",
    "    img = tifffile.imread(img_path)\n",
    "    masks = tifffile.imread(mask_path)\n",
    "    flows = tifffile.imread(flow_path)\n",
    "\n",
    "    plt.figure(figsize=(25,10))\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.title('image')\n",
    "    plt.subplot(2,3,2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(masks)\n",
    "    plt.title('mask')\n",
    "    for k in range(4):\n",
    "        plt.subplot(2,3,3+k)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(flows[k])\n",
    "        plt.title(f'flow {k}')\n",
    "    plt.show()\n",
    "    \n",
    "root = os.path.join(RAW_DATA,'sartorius-train-tif',f'fold_{FOLD}','train/') \n",
    "sample_paths = os.listdir(root)\n",
    "sample_paths = [x for x in sample_paths if 'img' in x]\n",
    "random.shuffle(sample_paths)\n",
    "for k in range(5):\n",
    "    img_path = sample_paths[k]\n",
    "    print(img_path)\n",
    "    plot_example(root+img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_load = 'cyto' ## cyto, cyto2, nuclei\n",
    "number_of_epochs = 500  ## Train more epochs for better results\n",
    "batch_size = 8\n",
    "initial_learning_rate = 0.0001\n",
    "Training_channel = 0 # For grayscale\n",
    "Second_training_channel= 0 \n",
    "train_folder = f'/tmp/cellpose_train/train'\n",
    "test_folder = f'/tmp/cellpose_train/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/cellpose_train/\n",
    "\n",
    "root = os.path.join(RAW_DATA,'sartorius-train-tif')\n",
    "!cp -r {root}/fold_{FOLD}/* /tmp/cellpose_train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls {train_folder} | wc -l\n",
    "!ls {test_folder} | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m cellpose \\\n",
    "            --train \\\n",
    "            --use_gpu \\\n",
    "            --fast_mode \\\n",
    "            --dir \"$train_folder\" --test_dir \"$test_folder\" \\\n",
    "            --pretrained_model $model_to_load \\\n",
    "            --chan $Training_channel --chan2 $Second_training_channel \\\n",
    "            --n_epochs $number_of_epochs \\\n",
    "            --learning_rate $initial_learning_rate \\\n",
    "            --batch_size $batch_size \\\n",
    "            --img_filter img \\\n",
    "            --mask_filter masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh /tmp/cellpose_train/train/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /tmp/cellpose_train/train/models ./models/fold_{FOLD}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference \n",
    "\n",
    "Refer: https://www.kaggle.com/slawekbiel/cellpose-inference-307-lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(f'models/fold_{FOLD}/*')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##----------Update this Manually\n",
    "model_path = 'models/fold_4/cellpose_residual_on_style_on_concatenation_off_train_2021_12_28_09_14_57.877627'\n",
    "\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile predict.py\n",
    "import sys\n",
    "import numpy as np\n",
    "from cellpose import models, io, plot\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import glob\n",
    "\n",
    "USE_GPU_FOR_INFERENCE = True\n",
    "\n",
    "def rle_encode(img):\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "test_files = glob.glob(f'/tmp/cellpose_train/val/*_img.tif')\n",
    "print(len(test_files))\n",
    "model = models.CellposeModel(gpu=USE_GPU_FOR_INFERENCE, pretrained_model=sys.argv[1])\n",
    "\n",
    "ids, masks = [],[]\n",
    "for fn in tqdm(test_files):\n",
    "    id_ = fn.split('/')[-1].replace('_img.tif','')\n",
    "    preds, flows, _ = model.eval(io.imread(fn), diameter=19, channels=[0,0], augment=True, resample=True)\n",
    "    for i in range (1, preds.max() + 1):\n",
    "        ids.append(id_)\n",
    "        masks.append(rle_encode(preds == i))\n",
    "FOLD = sys.argv[3]\n",
    "pd.DataFrame({'id':ids, 'predicted':masks}).to_csv(f'val_predictions_fold_{FOLD}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python predict.py {model_path} /tmp/cellpose_train/val {FOLD}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import skimage\n",
    "import skimage.segmentation\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rles_to_mask(encs, shape):\n",
    "    \"\"\"\n",
    "    Decodes a rle.\n",
    "\n",
    "    Args:\n",
    "        encs (list of str): Rles for each class.\n",
    "        shape (tuple [2]): Mask size.\n",
    "\n",
    "    Returns:\n",
    "        np array [shape]: Mask.\n",
    "    \"\"\"\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint)\n",
    "    if type(encs)==float:\n",
    "        return img\n",
    "    for m, enc in enumerate(encs):\n",
    "        if isinstance(enc, np.float) and np.isnan(enc):\n",
    "            continue\n",
    "        enc_split = enc.split()\n",
    "        for i in range(len(enc_split) // 2):\n",
    "            start = int(enc_split[2 * i]) - 1\n",
    "            length = int(enc_split[2 * i + 1])\n",
    "            img[start: start + length] = 1 + m\n",
    "    return img.reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 704\n",
    "height = 520\n",
    "shape = [height,width]\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "train_df = train_df.groupby('id').annotation.agg(list).reset_index()\n",
    "\n",
    "cellpose_predictions = pd.read_csv(f'val_predictions_fold_{FOLD}.csv')\n",
    "cellpose_predictions = cellpose_predictions.groupby('id').predicted.agg(list).reset_index()\n",
    "df = pd.merge(train_df,cellpose_predictions,on='id')\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in df.iterrows():\n",
    "    \n",
    "    print(row.id)\n",
    "    gt_masks = rles_to_mask(row.annotation, shape).astype(np.uint16)\n",
    "    predicted_masks = rles_to_mask(row.predicted, shape).astype(np.uint16)\n",
    "    \n",
    "    gt_masks = (gt_masks>0).astype(int)*(gt_masks%5)\n",
    "    predicted_masks = (predicted_masks>0).astype(int)*(predicted_masks%5)\n",
    "\n",
    "    _, axs = plt.subplots(1, 2, figsize=(36, 18))\n",
    "    axs = axs.flatten()\n",
    "    axs[0].imshow(gt_masks)\n",
    "    axs[1].imshow(predicted_masks)\n",
    "    plt.show()\n",
    "    \n",
    "    if i==4: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(labels, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the IoU for instance labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        labels (np array): Labels.\n",
    "        y_pred (np array): predictions\n",
    "\n",
    "    Returns:\n",
    "        np array: IoU matrix, of size true_objects x pred_objects.\n",
    "    \"\"\"\n",
    "\n",
    "    true_objects = len(np.unique(labels))\n",
    "    pred_objects = len(np.unique(y_pred))\n",
    "\n",
    "    # Compute intersection between all objects\n",
    "    intersection = np.histogram2d(\n",
    "        labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects)\n",
    "    )[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins=true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins=pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "    iou = intersection / union\n",
    "    \n",
    "    return iou[1:, 1:]  # exclude background\n",
    "\n",
    "def precision_at(threshold, iou):\n",
    "    \"\"\"\n",
    "    Computes the precision at a given threshold.\n",
    "\n",
    "    Args:\n",
    "        threshold (float): Threshold.\n",
    "        iou (np array [n_truths x n_preds]): IoU matrix.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of true positives,\n",
    "        int: Number of false positives,\n",
    "        int: Number of false negatives.\n",
    "    \"\"\"\n",
    "    matches = iou > threshold\n",
    "    true_positives = np.sum(matches, axis=1) >= 1  # Correct objects\n",
    "    false_negatives = np.sum(matches, axis=1) == 0  # Missed objects\n",
    "    false_positives = np.sum(matches, axis=0) == 0  # Extra objects\n",
    "    tp, fp, fn = (\n",
    "        np.sum(true_positives),\n",
    "        np.sum(false_positives),\n",
    "        np.sum(false_negatives),\n",
    "    )\n",
    "    return tp, fp, fn\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "def iou_map(truths, preds, verbose=0):\n",
    "    \"\"\"\n",
    "    Computes the metric for the competition.\n",
    "    Masks contain the segmented pixels where each object has one value associated,\n",
    "    and 0 is the background.\n",
    "\n",
    "    Args:\n",
    "        truths (list of masks): Ground truths.\n",
    "        preds (list of masks): Predictions.\n",
    "        verbose (int, optional): Whether to print infos. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        float: mAP.\n",
    "    \"\"\"\n",
    "    ious = [\n",
    "        compute_iou(rles_to_mask(truth,shape), rles_to_mask(pred,shape)) \n",
    "            for truth, pred in tqdm(zip(truths, preds))\n",
    "    ]\n",
    "    \n",
    "    if verbose:\n",
    "        print(ious[0].shape)\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrecision\\tRecall\")\n",
    "\n",
    "    prec = []\n",
    "    recalls = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tps, fps, fns = 0, 0, 0\n",
    "        for iou in ious:\n",
    "            tp, fp, fn = precision_at(t, iou)\n",
    "            tps += tp\n",
    "            fps += fp\n",
    "            fns += fn\n",
    "\n",
    "        p = tps / (tps + fps + fns)\n",
    "        r = tps / (tps + fns)\n",
    "        prec.append(p)\n",
    "        recalls.append(r)\n",
    "   \n",
    "        if verbose:\n",
    "            print(\"{:1.2f}\\t{}\\t{}\\t{}\\t{:1.3f}\\t{:1.3f}\".format(t, tps, fps, fns, p, r))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"AP\\t-\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "\n",
    "    return round(np.mean(prec),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = df.annotation.values\n",
    "predictions = df.predicted.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_map(annotations,predictions,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking perf. \n",
    "### fold-2  \n",
    "epochs=10, BS=8\n",
    "iou=0.3543  \n",
    "Epoch 9, Time 85.6s, Loss 0.5771, Loss Test 0.5457, LR 0.000  \n",
    "----\n",
    "epochs=50, BS=8\n",
    "iou=0.3818  \n",
    "Epoch 40, Time 313.2s, Loss 0.4704, Loss Test 0.4716, LR 0.0002\n",
    "##### Increasing epochs 10-->50, increases IoU by 7.7%\n",
    "##### Reducing BS from 8--->4 doesn't make any difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
